<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta charset="utf-8">
  <title>Alessandro Checco</title>

  <meta name="author" content="AlessandroChecco" />
  <meta name="description" content="" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <link rel="alternate" type="application/rss+xml" href="/atom.xml" />

  <link href="/vendor/css/bootstrap.min.css" rel="stylesheet">
  <link href="/vendor/css/font-awesome.min.css" rel="stylesheet">
  <link href="/vendor/css/academicons.min.css" rel="stylesheet">
  <link href="/vendor/pygments/default.css" rel="stylesheet">
  <link href="/css/bamos.css" rel="stylesheet">
  <link href="/css/sharingbuttons.css" rel="stylesheet">

  <meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<body>
	<div class="navbar navbar-default navbar-fixed-top">
		<div class="container">
			<div class="row">
				<div class="col-md-10 col-md-offset-1">
					<div class="navbar-header">
						  <a href="/" class="navbar-brand">
                  <div>
                      <img src="/images/me-face.jpg" class="img-circle"></img>
                      Alessandro Checco
                  </div>
              </a>
						<button class="navbar-toggle" type="button" data-toggle="collapse"
                    data-target="#navbar-main">
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
						</button>
					</div>
					<div class="navbar-collapse collapse" id="navbar-main">
						<ul class="nav navbar-nav">
							<li>
								<a href="/">About</a>
							</li>
							<li>
								<a href="/blog/">Blog</a>
							</li>
						</ul>
						<ul class="nav navbar-nav navbar-right" style="font-size: 1.5em">
							<li>
								<a href="http://github.com/AlessandroChecco" target="_blank">
									<i class="fa fa-lg fa-github"></i></a>
							</li>
							<li>
								<a href="http://twitter.com/alex_checco" target="_blank">
									<i class="fa fa-lg fa-twitter"></i></a>
							</li>
              <li>
                <a href="https://scholar.google.com/citations?user=crhkrNcAAAAJ" target="_blank">
                  <i class="ai ai-google-scholar"></i></a>
              </li>
              <li>
                  <a href="/atom.xml" target="_blank">
                      <i class="fa fa-rss"></i></a>
              </li>
						</ul>
					</div>
				</div>
			</div>
		</div>
	</div>

  <div class="container">
  <div class="row">
    <div class="col-md-6 col-md-offset-1 vcenter idxHdr">
      <div style='font-size: 2em; color: #4582ec; font-weight: bold; padding-bottom: 0.3em;'>Alessandro Checco</div>
      <div style='font-size: 1.2em;'>
        Researcher
      </div>
      <div style='font-size: 1.2em'>
        <a href="https://www.sheffield.ac.uk/is">Information School</a>
      </div>
      <div style='font-size: 1.2em'>
        <a href="https://www.sheffield.ac.uk">University of Sheffield</a>
      </div>
      <br/>

      <div style="padding: 0.3em; background-color: #4582ec; display: inline-block; border-radius: 4px; font-size: 1.2em;">
        <a href="data/cv.pdf" target='_blank' style='text-decoration: none;'>
          <i style='color: white' class="fa fa-download"></i>
        </a>
        <a href="https://github.com/AlessandroChecco" target='_blank' style='text-decoration: none;'>
          <i style='color: white' class="fa fa-code-fork"></i>
        </a>
        <a href="data/cv.pdf" target='_blank' style='color: white; text-decoration: none;'>CV</a>
      </div>

      <ul class="list-inline idxIcons" style='font-size: 1.9em; margin-top: 0.5em;'>
        <li>
          <a href="http://twitter.com/alex_checco" target="_blank">
            <i class="fa fa-fw fa-twitter"></i></a>
        </li>
        <li>
          <a href="https://scholar.google.com/citations?user=crhkrNcAAAAJ" target="_blank">
          <i class="ai ai-google-scholar"></i></a>
        </li>
        <li>
          <a href="https://www.facebook.com/alex.checco" target="_blank">
            <i class="fa fa-fw fa-facebook"></i></a>
        </li>
        <li>
          <a href="http://www.linkedin.com/in/alessandrochecco" target="_blank">
            <i class="fa fa-fw fa-linkedin"></i></a>
        </li>
        <li>
          <a href="/atom.xml" target="_blank">
            <i class="fa fa-fw fa-rss"></i></a>
        </li>
      </ul>
    </div>
    <div class="col-md-2 vcenter idxHdr">
      <a href="/images/me-large.jpg">
        <img src="/images/me.jpg"
             style="border-radius: 20px; margin: 10px; max-width: none;"
             alt="Me."/>
      </a>
    </div>
  </div>

  <div class="row">
    <div class="col-md-10 col-md-offset-1">
      <p>Mathematical engineer, particularly interested in graph theory, Markov chains, stochastic processes and randomised optmisation algorithms. Currently working on crowdsourcing, human computation and privacy issues in recommender systems. Also interested in high performance parallel computing and big data analysis.</p>

<h2 id="i-classfa-fa-chevron-righti-education"><i class="fa fa-chevron-right"></i> Education</h2>

<table class="table table-hover">
  <tr>
    <td class="col-md-3">Aug 2014 - Present</td>
    <td>
        <strong>Ph.D. in Computer Science</strong>
        <br />
      Hamilton Institute
    </td>
  </tr>
</table>

<h2 id="i-classfa-fa-chevron-righti-research-experience"><i class="fa fa-chevron-right"></i> Research Experience</h2>
<table class="table table-hover">
<tr>
  <td class="col-md-3">Apr 2016 - Present</td>
  <td>
    <strong>Carnegie Mellon University</strong>, Prof. Zico Kolter <br />
    Machine learning and optimization
  </td>
</tr>
<tr>
  <td class="col-md-3">Aug 2014 - Apr 2016</td>
  <td>
    <strong>Carnegie Mellon University</strong>, Prof. Mahadev Satyanarayanan <br />
    Applied machine learning and mobile systems
  </td>
</tr>
<tr>
  <td class="col-md-3">May 2012 - May 2014</td>
  <td>
    <strong>Virginia Tech</strong>, Prof. Jules White <br />
    Mobile systems, cyber-physical systems, and security
  </td>
</tr>
<tr>
  <td class="col-md-3">Jan 2013 - May 2014</td>
  <td>
    <strong>Virginia Tech</strong>, Prof. Layne Watson <br />
    Scientific computing, global/stochastic optimization, and bioinformatics
  </td>
</tr>
<tr>
  <td class="col-md-3">Nov 2012 - Mar 2014</td>
  <td>
    <strong>Virginia Tech</strong>, Prof. Binoy Ravindran <br />
    Heterogeneous compilers
  </td>
</tr>
</table>

<h2 id="i-classfa-fa-chevron-righti-selected-publications-a-hrefhttpsgithubcombamoscvblobmasterpublicationsselectedbibi-classfa-fa-code-fork-aria-hiddentrueia"><i class="fa fa-chevron-right"></i> Selected Publications <a href="https://github.com/bamos/cv/blob/master/publications/selected.bib"><i class="fa fa-code-fork" aria-hidden="true"></i></a></h2>

<p><a href="https://scholar.google.com/citations?user=crhkrNcAAAAJ" class="btn btn-primary" style="padding: 0.3em;">
  <i class="ai ai-google-scholar"></i> Google Scholar
</a></p>

<table class="table table-hover">

<tr>
<td class="col-md-3"><a href="http://arxiv.org/abs/1609.07152" target="_blank"><img src="images/publications/amos2016input.png" /></a> </td>
<td>
    <strong>Input Convex Neural Networks</strong><br />
    <strong>B. Amos</strong>, L. Xu, and J. Kolter<br />
    arXiv 2016<br />
    [1] 
[<a href="javascript: none" onclick="$(&quot;#abs_amos2016input&quot;).toggle()">abs</a>] [<a href="http://arxiv.org/abs/1609.07152" target="_blank">pdf</a>]  [<a href="https://github.com/locuslab/icnn" target="_blank">code</a>] <br />
    
<div id="abs_amos2016input" style="text-align: justify; display: none">
        <p>This paper presents the input convex neural network
architecture. These are scalar-valued (potentially deep) neural
networks with constraints on the network parameters such that the
output of the network is a convex function of (some of) the
inputs. The networks allow for efficient inference via optimization
over some inputs to the network given others, and can be applied to
settings including structured prediction, data imputation, reinforcement learning, and others. In this paper we lay the basic
groundwork for these models, proposing methods for inference, optimization and learning, and analyze their representational
power. We show that many existing neural network architectures can be
made input-convex with only minor modification, and develop
specialized optimization algorithms tailored to this setting. Finally, we highlight the performance of the methods on multi-label prediction, image completion, and reinforcement learning problems, where we show
improvement over the existing state of the art in many cases.</p>
      </div>

</td>
</tr>


<tr>
<td class="col-md-3"><a href="http://www.cs.cmu.edu/~hzhao1/papers/ICML2016/BL-SPN-main.pdf" target="_blank"><img src="images/publications/zhao2016collapsed.png" /></a> </td>
<td>
    <strong>Collapsed Variational Inference for Sum-Product Networks</strong><br />
    H. Zhao, T. Adel, G. Gordon, and <strong>B. Amos</strong><br />
    ICML 2016<br />
    [2] 
[<a href="javascript: none" onclick="$(&quot;#abs_zhao2016collapsed&quot;).toggle()">abs</a>] [<a href="http://www.cs.cmu.edu/~hzhao1/papers/ICML2016/BL-SPN-main.pdf" target="_blank">pdf</a>] <br />
    
<div id="abs_zhao2016collapsed" style="text-align: justify; display: none">
        <p>Sum-Product Networks (SPNs) are probabilistic inference machines that admit
exact inference in linear time in the size of the network. Existing
parameter learning approaches for SPNs are largely based on the maximum
likelihood principle and hence are subject to overfitting compared to
more Bayesian approaches. Exact Bayesian posterior inference for SPNs is
computationally intractable. Both standard variational inference and
posterior sampling for SPNs are computationally infeasible even for
networks of moderate size due to the large number of local latent
variables per instance. In this work, we propose a novel deterministic
collapsed variational inference algorithm for SPNs that is
computationally efficient, easy to implement and at the same time allows
us to incorporate prior information into the optimization formulation.
Extensive experiments show a significant improvement in accuracy compared
with a maximum likelihood based approach.</p>
      </div>

</td>
</tr>


<tr>
<td class="col-md-3"><a href="http://reports-archive.adm.cs.cmu.edu/anon/anon/2016/CMU-CS-16-118.pdf" target="_blank"><img src="images/publications/amos2016openface.png" /></a> </td>
<td>
    <strong>OpenFace: A general-purpose face recognition library with mobile applications</strong><br />
    <strong>B. Amos</strong>, B. Ludwiczuk, and M. Satyanarayanan<br />
    CMU 2016<br />
    [3] 
[<a href="javascript: none" onclick="$(&quot;#abs_amos2016openface&quot;).toggle()">abs</a>] [<a href="http://reports-archive.adm.cs.cmu.edu/anon/anon/2016/CMU-CS-16-118.pdf" target="_blank">pdf</a>]  [<a href="https://cmusatyalab.github.io/openface" target="_blank">code</a>] <br />
    
<div id="abs_amos2016openface" style="text-align: justify; display: none">
        <p>Cameras are becoming ubiquitous in the Internet of Things (IoT) and
can use face recognition technology to improve context. There is a
large accuracy gap between today’s publicly available face recognition
systems and the state-of-the-art private face recognition
systems. This paper presents our OpenFace face recognition library
that bridges this accuracy gap. We show that OpenFace provides
near-human accuracy on the LFW benchmark and present a new
classification benchmark for mobile scenarios. This paper is intended
for non-experts interested in using OpenFace and provides a light
introduction to the deep neural network techniques we use.</p>

        <p>We released OpenFace in October 2015 as an open source library under
the Apache 2.0 license. It is available at:
<a href="http://cmusatyalab.github.io/openface/">http://cmusatyalab.github.io/openface/</a></p>
      </div>

</td>
</tr>


<tr>
<td class="col-md-3"><a href="https://vtechworks.lib.vt.edu/bitstream/handle/10919/49672/qnTOMS14.pdf" target="_blank"><img src="images/publications/amos2014QNSTOP.png" /></a> </td>
<td>
    <strong>QNSTOP-QuasiNewton Algorithm for Stochastic Optimization</strong><br />
    <strong>B. Amos</strong>, D. Easterling, L. Watson, W. Thacker, B. Castle, and M. Trosset<br />
    VT 2014<br />
    [4] 
[<a href="javascript: none" onclick="$(&quot;#abs_amos2014QNSTOP&quot;).toggle()">abs</a>] [<a href="https://vtechworks.lib.vt.edu/bitstream/handle/10919/49672/qnTOMS14.pdf" target="_blank">pdf</a>] <br />
    
<div id="abs_amos2014QNSTOP" style="text-align: justify; display: none">
        <p>QNSTOP consists of serial and parallel (OpenMP) Fortran 2003 codes for the
quasi-Newton stochastic optimization method of Castle and Trosset. For
stochastic problems, convergence theory exists for the particular
algorithmic choices and parameter values used in QNSTOP. Both the parallel
driver subroutine, which offers several parallel decomposition strategies, and the serial driver subroutine can be used for stochastic optimization or
deterministic global optimization, based on an input switch. QNSTOP is
particularly effective for “noisy” deterministic problems, using only
objective function values. Some performance data for computational systems
biology problems is given.</p>
      </div>

</td>
</tr>


</table>

<h2 id="i-classfa-fa-chevron-righti-teaching-experience"><i class="fa fa-chevron-right"></i> Teaching Experience</h2>
<table class="table table-hover">
<tr>
  <td class="col-md-1">S2017</td>
  <td><strong>Graduate AI</strong> (CMU 15-780), TA</td>
</tr>
<tr>
  <td class="col-md-1">S2016</td>
  <td><strong>Distributed Systems</strong> (CMU 15-440/640), TA</td>
</tr>
<tr>
  <td class="col-md-1">S2013</td>
  <td><strong>Software Design and Data Structures</strong> (VT CS 2114), TA</td>
</tr>
</table>

<h2 id="i-classfa-fa-chevron-righti-industry-experience"><i class="fa fa-chevron-right"></i> Industry Experience</h2>
<table class="table table-hover">
<tr>
  <td class="col-md-3">May 2014 - Aug 2014</td>
  <td><strong>Adobe Research</strong>, Data Scientist Intern</td>
</tr>
<tr>
<td colspan="100%">
<ul>
<li>
          <p>I built a web analytics processing engine using <strong>Scala</strong>, <strong>Spark</strong>, <strong>Spray</strong>, <strong>Parquet</strong>, and <strong>HDFS</strong>.</p>
        </li>
</ul>
</td>
</tr>
<tr>
  <td class="col-md-3">Dec 2013 - Jan 2014</td>
  <td><strong>Snowplow Analytics</strong>, Software Engineer Intern</td>
</tr>
<tr>
<td colspan="100%">
<ul>
<li>
          <p>Open-source <strong>Scala</strong> development with a startup on the Snowplow analytics platform. My commits are online at <a href="https://github.com/snowplow/snowplow/commits?author=bamos">https://github.com/snowplow/snowplow/commits?author=bamos</a>.</p>
        </li>
<li>
          <p>Developed a new server using <strong>Spray</strong> and <strong>Actors</strong> to store <strong>Thrift</strong> events on <strong>Amazon Kinesis</strong>.</p>
        </li>
</ul>
</td>
</tr>
<tr>
  <td class="col-md-3">May 2013 - Aug 2013</td>
  <td><strong>Qualcomm</strong>, Software Engineer Intern</td>
</tr>
<tr>
<td colspan="100%">
<ul>
<li>
          <p>I created a specification format language translator for fuzz testing with Python.</p>
        </li>
</ul>
</td>
</tr>
<tr>
  <td class="col-md-3">May 2012 - Aug 2012</td>
  <td><strong>Phoenix Integration</strong>, Software Engineer Intern</td>
</tr>
<tr>
<td colspan="100%">
<ul>
<li>
          <p>I developed industry software for software integration and design process optimization in <strong>VC++</strong>, <strong>VC#</strong>, and <strong>Java</strong>.</p>
        </li>
</ul>
</td>
</tr>
<tr>
  <td class="col-md-3">Jan 2011 - Aug 2011</td>
  <td><strong>Sunapsys</strong>, Network Administrator Intern</td>
</tr>
<tr>
<td colspan="100%">
<ul>
<li>
          <p>Internship in high school to replace Windows domain, mail, DHCP, and DNS servers with virtual <strong>Linux</strong> servers using <strong>KVM</strong> and <strong>virsh</strong>.</p>
        </li>
</ul>
</td>
</tr>
</table>

<h2 id="i-classfa-fa-chevron-righti-skills"><i class="fa fa-chevron-right"></i> Skills</h2>
<table class="table table-hover">
<tr>
  <td class="col-md-2">Languages</td>
  <td>
      <p>Bash, C, C++, CSS, Matlab, JavaScript, Fortran, HTML, LaTeX, <em>Mathematica</em>, Python, R</p>
    </td>
</tr>
<tr>
  <td class="col-md-2">Frameworks</td>
  <td>
      <p>Spark, Cloudera, Pandas, NumPy, SciPy, SimPy, scikit-learn</p>
    </td>
</tr>
<tr>
  <td class="col-md-2">Algorithm design</td>
  <td>
      <p>Design, convergence rate and complexity analysis of decentralised algorithms on graphs.</p>
    </td>
</tr>
<tr>
  <td class="col-md-2">Convex optimisation</td>
  <td>
      <p>Convex optimisation, with application to discrete problems. Numerical methods for approximate solution of optimisation problems.</p>
    </td>
</tr>
<tr>
  <td class="col-md-2">Data Mining</td>
  <td>
      <p>Monte Carlo Markov chains techniques for data mining and feature selection, applied to medical diagnostic and artificial olfaction.</p>
    </td>
</tr>
<tr>
  <td class="col-md-2">Privacy in recommender systems</td>
  <td>
      <p>Probabilistic matrix factorisation applied to recommender systems, with focus on privacy issues.</p>
    </td>
</tr>
<tr>
  <td class="col-md-2">Simulatots</td>
  <td>
      <p>Event-based simulators design for wireless network analysis.</p>
    </td>
</tr>
<tr>
  <td class="col-md-2">Statistical inference</td>
  <td>
      <p>Bayesian modelling and exploratory data analysis, with focus on big data.</p>
    </td>
</tr>
</table>

<h2 id="i-classfa-fa-chevron-righti-cmu-graduate-coursework"><i class="fa fa-chevron-right"></i> CMU Graduate Coursework</h2>
<ul>
  <li>Statistical Machine Learning (10-702, Au), L. Wasserman, S2017</li>
  <li>Deep Reinforcement Learning (10-703), R. Salakhutdinov and A. Fragkiadaki, S2017</li>
  <li>Intermediate Statistics (10-705, Au), L. Wasserman, F2016</li>
  <li>Topics in Deep Learning (10-807), R. Salakhutdinov, F2016</li>
  <li>Convex Optimization (10-725), R. J. Tibshirani, F2015</li>
  <li>Algorithms in the Real World (15-853), G. Blelloch and A. Gupta, F2015</li>
  <li>Semantics of Programming Languages (15-812), A. Platzer, S2015</li>
  <li>Optimizing Compilers for Modern Architecture (15-745), T. Mowry, S2015</li>
  <li>Advanced Operating and Distributed Systems (15-712), D. Andersen, F2014</li>
  <li>Mobile and Pervasive Computing (15-812), M. Satyanarayanan and D. Siewiorek, F2014</li>
</ul>

<h2 id="i-classfa-fa-chevron-righti-honors--awards"><i class="fa fa-chevron-right"></i> Honors &amp; Awards</h2>
<table class="table table-hover">
<tr>
  <td class="col-md-2">2016 - 2019</td>
  <td>
    NSF Graduate Research Fellowship
    <!--  -->
  </td>
</tr>
<tr>
  <td class="col-md-2">2014</td>
  <td>
    1st Place Undergraduate Senior Capstone Award, Virginia Tech Computer Science
    <!--  -->
  </td>
</tr>
<tr>
  <td class="col-md-2">2014</td>
  <td>
    David Heilman Research Award, Virginia Tech Computer Science
    <!--  -->
  </td>
</tr>
<tr>
  <td class="col-md-2">2014</td>
  <td>
    Senior Scholar Award, Virginia Tech Computer Science
    <!--  -->
  </td>
</tr>
<tr>
  <td class="col-md-2">2014</td>
  <td>
    Honorable Mention, CRA Outstanding Undergraduate Researcher Award
    <!--  -->
  </td>
</tr>
<tr>
  <td class="col-md-2">2011 - 2014</td>
  <td>
    Awarded eight undergraduate merit scholarships
    <!--  -->
  </td>
</tr>
</table>

<h2 id="i-classfa-fa-chevron-righti-all-publications-a-hrefhttpsgithubcombamoscvblobmasterpublicationsi-classfa-fa-code-fork-aria-hiddentrueia"><i class="fa fa-chevron-right"></i> All Publications <a href="https://github.com/bamos/cv/blob/master/publications/"><i class="fa fa-code-fork" aria-hidden="true"></i></a></h2>

<p><a href="https://scholar.google.com/citations?user=crhkrNcAAAAJ" class="btn btn-primary" style="padding: 0.3em;">
  <i class="ai ai-google-scholar"></i> Google Scholar
</a></p>

<h3 id="conference-proceedings-a-hrefhttpsgithubcombamoscvblobmasterpublicationsconferencebibi-classfa-fa-code-fork-aria-hiddentrueia">Conference Proceedings <a href="https://github.com/bamos/cv/blob/master/publications/conference.bib"><i class="fa fa-code-fork" aria-hidden="true"></i></a></h3>

<table class="table table-hover">

<tr>
<td>
    <strong>Collapsed Variational Inference for Sum-Product Networks</strong><br />
    H. Zhao, T. Adel, G. Gordon, and <strong>B. Amos</strong><br />
    ICML 2016<br />
    [C1] 
[<a href="javascript: none" onclick="$(&quot;#abs_zhao2016collapsedC&quot;).toggle()">abs</a>] [<a href="http://www.cs.cmu.edu/~hzhao1/papers/ICML2016/BL-SPN-main.pdf" target="_blank">pdf</a>] <br />
    
<div id="abs_zhao2016collapsedC" style="text-align: justify; display: none">
        <p>Sum-Product Networks (SPNs) are probabilistic inference machines that admit
exact inference in linear time in the size of the network. Existing
parameter learning approaches for SPNs are largely based on the maximum
likelihood principle and hence are subject to overfitting compared to
more Bayesian approaches. Exact Bayesian posterior inference for SPNs is
computationally intractable. Both standard variational inference and
posterior sampling for SPNs are computationally infeasible even for
networks of moderate size due to the large number of local latent
variables per instance. In this work, we propose a novel deterministic
collapsed variational inference algorithm for SPNs that is
computationally efficient, easy to implement and at the same time allows
us to incorporate prior information into the optimization formulation.
Extensive experiments show a significant improvement in accuracy compared
with a maximum likelihood based approach.</p>
      </div>

</td>
</tr>


<tr>
<td>
    <strong>Applying machine learning classifiers to dynamic Android malware detection at scale</strong><br />
    <strong>B. Amos</strong>, H. Turner, and J. White<br />
    IWCMC 2013<br />
    [C2] 
[<a href="javascript: none" onclick="$(&quot;#abs_amos2013applyingC&quot;).toggle()">abs</a>] [<a href="http://bamos.github.io/data/papers/amos-iwcmc2013.pdf" target="_blank">pdf</a>]  [<a href="https://github.com/VT-Magnum-Research/antimalware" target="_blank">code</a>] <br />
    
<div id="abs_amos2013applyingC" style="text-align: justify; display: none">
        <p>The widespread adoption and contextually sensitive
nature of smartphone devices has increased concerns over smartphone
malware. Machine learning classifiers are a current method
for detecting malicious applications on smartphone systems. This
paper presents the evaluation of a number of existing classifiers, using a dataset containing thousands of real (i.e. not synthetic)
applications. We also present our STREAM framework, which
was developed to enable rapid large-scale validation of mobile
malware machine learning classifiers.</p>
      </div>

</td>
</tr>


</table>

<h3 id="workshop-symposium-and-short-papers-a-hrefhttpsgithubcombamoscvblobmasterpublicationsshortbibi-classfa-fa-code-fork-aria-hiddentrueia">Workshop, Symposium, and Short Papers <a href="https://github.com/bamos/cv/blob/master/publications/short.bib"><i class="fa fa-code-fork" aria-hidden="true"></i></a></h3>

<table class="table table-hover">

<tr>
<td>
    <strong>Privacy mediators: helping IoT cross the chasm</strong><br />
    N. Davies, N. Taft, M. Satyanarayanan, S. Clinch, and <strong>B. Amos</strong><br />
    HotMobile 2016<br />
    [W1] 
[<a href="javascript: none" onclick="$(&quot;#abs_davies2016privacyW&quot;).toggle()">abs</a>] [<a href="http://eprints.lancs.ac.uk/78255/1/44691.pdf" target="_blank">pdf</a>] <br />
    
<div id="abs_davies2016privacyW" style="text-align: justify; display: none">
        <p>Unease over data privacy will retard consumer acceptance of IoT
deployments. The primary source of discomfort is a lack of user
control over raw data that is streamed directly from sensors to the
cloud. This is a direct consequence of the over-centralization of
today’s cloud-based IoT hub designs. We propose a solution that
interposes a locally-controlled software component called a privacy
mediator on every raw sensor stream. Each mediator is in the same
administrative domain as the sensors whose data is being collected, and dynamically enforces the current privacy policies of the owners
of the sensors or mobile users within the domain. This solution necessitates
a logical point of presence for mediators within the administrative
boundaries of each organization. Such points of presence
are provided by cloudlets, which are small locally-administered data
centers at the edge of the Internet that can support code mobility.
The use of cloudlet-based mediators aligns well with natural personal
and organizational boundaries of trust and responsibility.</p>
      </div>

</td>
</tr>


<tr>
<td>
    <strong>Early Implementation Experience with Wearable Cognitive Assistance Applications</strong><br />
    Z. Chen, L. Jiang, W. Hu, K. Ha, <strong>B. Amos</strong>, P. Pillai, A. Hauptmann, and M. Satyanarayanan<br />
    WearSys 2015<br />
    [W2] 
[<a href="javascript: none" onclick="$(&quot;#abs_chen2015earlyW&quot;).toggle()">abs</a>] [<a href="http://www.cs.cmu.edu/~satya/docdir/chen-wearsys2015.pdf" target="_blank">pdf</a>] <br />
    
<div id="abs_chen2015earlyW" style="text-align: justify; display: none">
        <p>A cognitive assistance application combines a wearable device such
as Google Glass with cloudlet processing to provide step-by-step
guidance on a complex task. In this paper, we focus on user assistance
for narrow and well-defined tasks that require specialized
knowledge and/or skills. We describe proof-of-concept implementations
for four different tasks: assembling 2D Lego models, freehand
sketching, playing ping-pong, and recommending context-relevant
YouTube tutorials. We then reflect on the difficulties we faced in
building these applications, and suggest future research that could
simplify the creation of similar applications.</p>
      </div>

</td>
</tr>


<tr>
<td>
    <strong>The Case for Offload Shaping</strong><br />
    W. Hu, <strong>B. Amos</strong>, Z. Chen, K. Ha, W. Richter, P. Pillai, B. Gilbert, J. Harkes, and M. Satyanarayanan<br />
    HotMobile 2015<br />
    [W3] 
[<a href="javascript: none" onclick="$(&quot;#abs_hu2014caseW&quot;).toggle()">abs</a>] [<a href="http://www.cs.cmu.edu/~satya/docdir/hu-hotmobile2015.pdf" target="_blank">pdf</a>] <br />
    
<div id="abs_hu2014caseW" style="text-align: justify; display: none">
        <p>When offloading computation from a mobile device, we show
that it can pay to perform additional on-device work in order
to reduce the offloading workload. We call this offload shaping, and demonstrate its application at many different levels
of abstraction using a variety of techniques. We show that
offload shaping can produce significant reduction in resource
demand, with little loss of application-level fidelity</p>
      </div>

</td>
</tr>


<tr>
<td>
    <strong>Performance study of Spindle, a web analytics query engine implemented in Spark</strong><br />
    <strong>B. Amos</strong> and D. Tompkins<br />
    CloudCom 2014<br />
    [W4] 
[<a href="javascript: none" onclick="$(&quot;#abs_amos2014performanceW&quot;).toggle()">abs</a>] [<a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7037709" target="_blank">pdf</a>]  [<a href="https://github.com/adobe-research/spindle" target="_blank">code</a>] <br />
    
<div id="abs_amos2014performanceW" style="text-align: justify; display: none">
        <p>This paper shares our experiences building and benchmarking Spindle as an open
source Spark-based web analytics platform. Spindle’s design has been
motivated by real-world queries and data requiring concurrent, low latency
query execution. We identify a search space of Spark tuning options and study
their impact on Spark’s performance. Results from a self-hosted six node
cluster with one week of analytics data (13.1GB) indicate tuning options such
as proper partitioning can cause a 5x performance improvement.</p>
      </div>

</td>
</tr>


<tr>
<td>
    <strong>Global Parameter Estimation for a Eukaryotic Cell Cycle Model in Systems Biology</strong><br />
    T. Andrew, <strong>B. Amos</strong>, D. Easterling, C. Oguz, W. Baumann, J. Tyson, and L. Watson<br />
    SummerSim 2014<br />
    [W5] 
[<a href="javascript: none" onclick="$(&quot;#abs_andrew2014globalW&quot;).toggle()">abs</a>] [<a href="http://dl.acm.org/citation.cfm?id=2685662" target="_blank">pdf</a>] <br />
    
<div id="abs_andrew2014globalW" style="text-align: justify; display: none">
        <p>The complicated process by which a yeast cell divides, known as the cell
cycle, has been modeled by a system of 26 nonlinear ordinary differential
equations (ODEs) with 149 parameters. This model captures the chemical
kinetics of the regulatory networks controlling the cell division process
in budding yeast cells. Empirical data is discrete and matched against
discrete inferences (e.g., whether a particular mutant cell lives or dies)
computed from the ODE solution trajectories. The problem of
estimating the ODE parameters to best fit the model to the data is a
149-dimensional global optimization problem attacked by the deterministic
algorithm VTDIRECT95 and by the nondeterministic algorithms differential
evolution, QNSTOP, and simulated annealing, whose performances are
compared.</p>
      </div>

</td>
</tr>


<tr>
<td>
    <strong>Fortran 95 implementation of QNSTOP for global and stochastic optimization</strong><br />
    <strong>B. Amos</strong>, D. Easterling, L. Watson, B. Castle, M. Trosset, and W. Thacker<br />
    SpringSim (HPC) 2014<br />
    [W6] 
[<a href="javascript: none" onclick="$(&quot;#abs_amos2014fortranW&quot;).toggle()">abs</a>] [<a href="http://dl.acm.org/citation.cfm?id=2663525" target="_blank">pdf</a>] <br />
    
<div id="abs_amos2014fortranW" style="text-align: justify; display: none">
        <p>A serial Fortran 95 implementation of the QNSTOP algorithm is presented.
QNSTOP is a class of quasi-Newton methods for stochastic optimization with
variations for deterministic global optimization. This discussion provides
results from testing on various deterministic and stochastic optimization
functions.</p>
      </div>

</td>
</tr>


</table>

<h3 id="magazine-articles-a-hrefhttpsgithubcombamoscvblobmasterpublicationsmagazinebibi-classfa-fa-code-fork-aria-hiddentrueia">Magazine Articles <a href="https://github.com/bamos/cv/blob/master/publications/magazine.bib"><i class="fa fa-code-fork" aria-hidden="true"></i></a></h3>

<table class="table table-hover">

<tr>
<td>
    <strong>Edge Analytics in the Internet of Things</strong><br />
    M. Satyanarayanan, P. Simoens, Y. Xiao, P. Pillai, Z. Chen, K. Ha, W. Hu, and <strong>B. Amos</strong><br />
    IEEE Pervasive Computing 2015<br />
    [M1] 
[<a href="javascript: none" onclick="$(&quot;#abs_satyanarayanan2015edgeM&quot;).toggle()">abs</a>] [<a href="https://www.cs.cmu.edu/~satya/docdir/satya-edge2015.pdf" target="_blank">pdf</a>] <br />
    
<div id="abs_satyanarayanan2015edgeM" style="text-align: justify; display: none">
        <p>High-data-rate sensors, such as video cameras, are becoming ubiquitous in the
Internet of Things. This article describes GigaSight, an Internet-scale
repository of crowd-sourced video content, with strong enforcement of privacy
preferences and access controls. The GigaSight architecture is a federated
system of VM-based cloudlets that perform video analytics at the edge of the
Internet, thus reducing the demand for ingress bandwidth into the cloud.
Denaturing, which is an owner-specific reduction in fidelity of video content
to preserve privacy, is one form of analytics on cloudlets. Content-based
indexing for search is another form of cloudlet-based analytics. This article
is part of a special issue on smart spaces.</p>
      </div>

</td>
</tr>


<tr>
<td>
    <strong>Bad Parts: Are Our Manufacturing Systems at Risk of Silent Cyberattacks?</strong><br />
    H. Turner, J. White, J. Camelio, C. Williams, <strong>B. Amos</strong>, and R. Parker<br />
    IEEE Security &amp; Privacy 2015<br />
    [M2] 
[<a href="javascript: none" onclick="$(&quot;#abs_turner2015badM&quot;).toggle()">abs</a>] [<a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7118094" target="_blank">pdf</a>] <br />
    
<div id="abs_turner2015badM" style="text-align: justify; display: none">
        <p>Recent cyberattacks have highlighted the risk of physical equipment operating
outside designed tolerances to produce catastrophic failures. A related
threat is cyberattacks that change the design and manufacturing of a
machine’s part, such as an automobile brake component, so it no longer
functions properly. These risks stem from the lack of cyber-physical models
to identify ongoing attacks as well as the lack of rigorous application of
known cybersecurity best practices. To protect manufacturing processes in the
future, research will be needed on a number of critical cyber-physical
manufacturing security topics.</p>
      </div>

</td>
</tr>


</table>

<h3 id="tech-reports-a-hrefhttpsgithubcombamoscvblobmasterpublicationstech-reportsbibi-classfa-fa-code-fork-aria-hiddentrueia">Tech Reports <a href="https://github.com/bamos/cv/blob/master/publications/tech-reports.bib"><i class="fa fa-code-fork" aria-hidden="true"></i></a></h3>

<table class="table table-hover">

<tr>
<td>
    <strong>OpenFace: A general-purpose face recognition library with mobile applications</strong><br />
    <strong>B. Amos</strong>, B. Ludwiczuk, and M. Satyanarayanan<br />
    CMU 2016<br />
    [T1] 
[<a href="javascript: none" onclick="$(&quot;#abs_amos2016openfaceT&quot;).toggle()">abs</a>] [<a href="http://reports-archive.adm.cs.cmu.edu/anon/anon/2016/CMU-CS-16-118.pdf" target="_blank">pdf</a>]  [<a href="https://cmusatyalab.github.io/openface" target="_blank">code</a>] <br />
    
<div id="abs_amos2016openfaceT" style="text-align: justify; display: none">
        <p>Cameras are becoming ubiquitous in the Internet of Things (IoT) and
can use face recognition technology to improve context. There is a
large accuracy gap between today’s publicly available face recognition
systems and the state-of-the-art private face recognition
systems. This paper presents our OpenFace face recognition library
that bridges this accuracy gap. We show that OpenFace provides
near-human accuracy on the LFW benchmark and present a new
classification benchmark for mobile scenarios. This paper is intended
for non-experts interested in using OpenFace and provides a light
introduction to the deep neural network techniques we use.</p>

        <p>We released OpenFace in October 2015 as an open source library under
the Apache 2.0 license. It is available at:
<a href="http://cmusatyalab.github.io/openface/">http://cmusatyalab.github.io/openface/</a></p>
      </div>

</td>
</tr>


<tr>
<td>
    <strong>Are Cloudlets Necessary?</strong><br />
    Y. Gao, W. Hu, K. Ha, <strong>B. Amos</strong>, P. Pillai, and M. Satyanarayanan<br />
    CMU 2015<br />
    [T2] 
[<a href="javascript: none" onclick="$(&quot;#abs_gao2015cloudletsT&quot;).toggle()">abs</a>] [<a href="http://reports-archive.adm.cs.cmu.edu/anon/anon/2015/CMU-CS-15-139.pdf" target="_blank">pdf</a>] <br />
    
<div id="abs_gao2015cloudletsT" style="text-align: justify; display: none">
        <p>We present experimental results from Wi-Fi and 4G LTE networks to validate the
intuition that low end-to-end latency of cloud services improves application
response time and reduces energy consumption on mobile devices. We focus
specifically on computational offloading as a cloud service. Using a wide
range of applications, and exploring both pre-partitioned and dynamically
partitioned approaches, we demonstrate the importance of low latency for
cloud offload services. We show the best performance is achieved by
offloading to cloudlets, which are small-scale edge-located data centers. Our
results show that cloudlets can improve response times 51% and reduce energy
consumption in a mobile device by up to 42% compared to cloud offload.</p>
      </div>

</td>
</tr>


<tr>
<td>
    <strong>Adaptive VM handoff across cloudlets</strong><br />
    K. Ha, Y. Abe, Z. Chen, W. Hu, <strong>B. Amos</strong>, P. Pillai, and M. Satyanarayanan<br />
    CMU 2015<br />
    [T3] 
[<a href="javascript: none" onclick="$(&quot;#abs_ha2015adaptiveT&quot;).toggle()">abs</a>] [<a href="http://ra.adm.cs.cmu.edu/anon/2015/CMU-CS-15-113.pdf" target="_blank">pdf</a>] <br />
    
<div id="abs_ha2015adaptiveT" style="text-align: justify; display: none">
        <p>Cloudlet offload is a valuable technique for ensuring low end-to-end latency of
resource-intensive cloud processing for many emerging mobile applications.
This paper examines the impact of user mobility on cloudlet offload, and
shows that even modest user mobility can result in significant network
degradation. We propose VM handoff as a technique for seamlessly transferring
VMencapsulated execution to a more optimal offload site as users move. Our
approach can perform handoff in roughly a minute even over limited WANs by
adaptively reducing data transferred. We present experimental results to
validate our implementation and to demonstrate effectiveness of adaptation to
changing network conditions and processing capacity</p>
      </div>

</td>
</tr>


<tr>
<td>
    <strong>QNSTOP-QuasiNewton Algorithm for Stochastic Optimization</strong><br />
    <strong>B. Amos</strong>, D. Easterling, L. Watson, W. Thacker, B. Castle, and M. Trosset<br />
    VT 2014<br />
    [T4] 
[<a href="javascript: none" onclick="$(&quot;#abs_amos2014QNSTOPT&quot;).toggle()">abs</a>] [<a href="https://vtechworks.lib.vt.edu/bitstream/handle/10919/49672/qnTOMS14.pdf" target="_blank">pdf</a>] <br />
    
<div id="abs_amos2014QNSTOPT" style="text-align: justify; display: none">
        <p>QNSTOP consists of serial and parallel (OpenMP) Fortran 2003 codes for the
quasi-Newton stochastic optimization method of Castle and Trosset. For
stochastic problems, convergence theory exists for the particular
algorithmic choices and parameter values used in QNSTOP. Both the parallel
driver subroutine, which offers several parallel decomposition strategies, and the serial driver subroutine can be used for stochastic optimization or
deterministic global optimization, based on an input switch. QNSTOP is
particularly effective for “noisy” deterministic problems, using only
objective function values. Some performance data for computational systems
biology problems is given.</p>
      </div>

</td>
</tr>


</table>

<h3 id="posters-a-hrefhttpsgithubcombamoscvblobmasterpublicationspostersbibi-classfa-fa-code-fork-aria-hiddentrueia">Posters <a href="https://github.com/bamos/cv/blob/master/publications/posters.bib"><i class="fa fa-code-fork" aria-hidden="true"></i></a></h3>

<table class="table table-hover">

<tr>
<td>
    <strong>Input-Convex Deep Networks</strong><br />
    <strong>B. Amos</strong> and J. Kolter<br />
    ICLR Workshop 2016<br />
    [P1] [<a href="http://bamos.github.io/data/posters/2016-iclr-icnn.pdf" target="_blank">pdf</a>] <br />
    
</td>
</tr>


<tr>
<td>
    <strong>Face Recognition for Context Sensitive IoT Systems</strong><br />
    <strong>B. Amos</strong> and M. Satyanarayanan<br />
    HotMobile 2016<br />
    [P2] [<a href="http://bamos.github.io/data/posters/2016-hotmobile-facerec.pdf" target="_blank">pdf</a>]  [<a href="https://cmusatyalab.github.io/openface" target="_blank">code</a>] <br />
    
</td>
</tr>


</table>

<h2 id="i-classfa-fa-chevron-righti-recent-blog-posts"><i class="fa fa-chevron-right"></i> Recent Blog Posts</h2>

<table class="table table-hover">
  
    
    <tr>
      <td><a href="/2017/03/17/test/">Test blog post</a></td>
      <td class="col-md-3" style="text-align: right;">March 17, 2017</td>
    </tr>
    
  
</table>
<h4><a href="/blog">View all</a></h4>

<!---
## <i class="fa fa-chevron-right"></i> Fun Side Projects
+ [CS conference tracker](https://github.com/bamos/conference-tracker).
+ [SnowGlobe](https://github.com/bamos/snowglobe):
  Haskell-driven, small-scale web analytics with minimal configuration.
+ [My reading list](http://bamos.github.io/reading-list/):
  YAML data and hosted on GitHub pages.
+ [dotfiles](https://github.com/bamos/dotfiles):
  &hearts;
  [Arch Linux](https://www.archlinux.org/),
  OSX,
  [mutt](http://www.mutt.org/),
  [xmonad](http://xmonad.org/),
  [i3](https://i3wm.org/),
  [vim](http://www.vim.org/),
  [emacs](https://www.gnu.org/software/emacs/),
  [zsh](http://www.zsh.org/),
  [mpv](http://mpv.io/),
  [cmus](https://cmus.github.io/).
+ [girl](https://github.com/bamos/girl):
  Scala program to find broken links in GitHub projects.
+ [zsh-history-analysis](https://github.com/bamos/zsh-history-analysis):
  Analyze shell usage patterns with Python and R.
+ [python-scripts](https://github.com/bamos/python-scripts):
  Short and fun Python scripts.
+ [This website](https://github.com/bamos/bamos.github.io):
  Built with Jekyll and hosted on GitHub pages.
+ [cv](https://github.com/bamos/cv):
  Python-driven resume-curriculum vitae with Jinja templates.
+ [yaml-mailer](https://github.com/bamos/yaml-mailer):
  Email many people different messages.
+ [latex-templates](https://github.com/bamos/latex-templates)
  and [beamer-snippets](https://github.com/bamos/beamer-snippets):
  Personal collection and previewing of LaTeX and Beamer snippets.
  Admittedly, I now use Keynote for presentations.
-->

<hr />

<p>Last updated on 2017-03-17</p>


    </div>
  </div>
</div>


  <script src="/js/sp.js"></script>
  <script src="/vendor/js/jquery.min.js"></script>
  <script src="/vendor/js/bootstrap.min.js"></script>
  <script src="/vendor/js/anchor.min.js"></script>
  <script src="/vendor/js/jquery.toc.js"></script>
  <script type="text/javascript">
   try {
       var snowplowTracker = Snowplow.getTrackerUrl('joule.isr.cs.cmu.edu:8081');
       snowplowTracker.enableLinkTracking();
       snowplowTracker.trackPageView();
   } catch (err) {}

   $("#toc").toc({
       'headings': 'h2,h3'
   });
   anchors.add('h2,h3');
  </script>

</body>

</html>
